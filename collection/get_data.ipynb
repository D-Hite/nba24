{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6233cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nba_api.stats.endpoints as ep\n",
    "import datetime\n",
    "import re\n",
    "from os import path\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lshelper(game_arr, gd):\n",
    "    for x in range(len(game_arr)):\n",
    "        gid = game_arr[x, 4]\n",
    "        match = game_arr[x, 6]\n",
    "        pm = game_arr[x, 27]\n",
    "        if game_arr[x, 7] == 'W':\n",
    "            winner = game_arr[x, 2]\n",
    "        else:\n",
    "            winner = game_arr[x, 6][-3:]\n",
    "        gd[gid] = (match, pm, winner)\n",
    "    return gd\n",
    "\n",
    "\n",
    "class StatBucket():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.clog = None\n",
    "        self.log = None\n",
    "        self.oslog = None\n",
    "        self.outcomes = None\n",
    "        self.data = None\n",
    "        self.season = None\n",
    "        self.gidset = None\n",
    "        self.FD = {'advanced':ep.boxscoreadvancedv2.BoxScoreAdvancedV2,\n",
    "     'fourfactors':ep.boxscorefourfactorsv2.BoxScoreFourFactorsV2,\n",
    "     'misc':ep.boxscoremiscv2.BoxScoreMiscV2,\n",
    "     'scoring':ep.boxscorescoringv2.BoxScoreScoringV2,\n",
    "     'summary':ep.boxscoresummaryv2.BoxScoreSummaryV2,\n",
    "     'traditional':ep.boxscoretraditionalv2.BoxScoreTraditionalV2\n",
    "    }\n",
    "\n",
    "    def update_log(self, season):\n",
    "        self.season=season\n",
    "        result = ep.leaguegamefinder.LeagueGameFinder(season_nullable=season)\n",
    "        all_games = result.get_data_frames()[0]\n",
    "        rs = all_games[all_games.SEASON_ID == '2' + season[:4]]\n",
    "        rs = rs[rs.GAME_ID.str[:3] == '002'] #may need to update\n",
    "        os = all_games[all_games.SEASON_ID == '4' + season[:4]]\n",
    "        os = os[os.GAME_ID.str[:3] == '004']\n",
    "        self.log = rs\n",
    "        self.oslog = os\n",
    "#         self.clog = rs.append(os)\n",
    "        self.clog = pd.concat([rs,os])\n",
    "    \n",
    "    \n",
    "    def get_log_stats(self):\n",
    "        game_arr = self.log.to_numpy()\n",
    "        os_arr = self.oslog.to_numpy()\n",
    "        game_dat = dict()\n",
    "        game_dat = lshelper(game_arr, game_dat)\n",
    "        res = lshelper(os_arr, game_dat)        \n",
    "        self.outcomes = res\n",
    "        self.gidset = set(res.keys())\n",
    "\n",
    "    def write_out(self, f, tstats, pstats):\n",
    "        # IF V3\n",
    "        try:\n",
    "            # if f == 'traditional':\n",
    "            #     tstats.sort_values('teamId', inplace=True, kind='mergesort')\n",
    "            #     tstats.sort_values('gameId', inplace=True, kind='mergesort')\n",
    "            #     tstats.to_csv(f'DATA/raw/teams/{f}/{f}{self.season}.csv', index=False)\n",
    "            #     pstats.sort_values('teamId', inplace=True, kind='mergesort')\n",
    "            #     pstats.sort_values('gameId', inplace=True, kind='mergesort')\n",
    "            #     pstats.to_csv(f'DATA/raw/players/{f}/{f}{self.season}.csv', index=False)\n",
    "            # else:\n",
    "            tstats.sort_values('TEAM_ID', inplace=True, kind='mergesort')\n",
    "            tstats.sort_values('GAME_ID', inplace=True, kind='mergesort')\n",
    "            tstats.to_csv(f'DATA/raw/teams/{f}/{f}{self.season}.csv', index=False)\n",
    "            pstats.sort_values('TEAM_ID', inplace=True, kind='mergesort')\n",
    "            pstats.sort_values('GAME_ID', inplace=True, kind='mergesort')\n",
    "            pstats.to_csv(f'DATA/raw/players/{f}/{f}{SEASONS[i]}.csv', index=False)\n",
    "            \n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f'error with write out for {f}{self.season}\\n{e}\\n')\n",
    "            \n",
    "            return\n",
    "\n",
    "\n",
    "    def Season_csv_update(self,endpoint_name):\n",
    "        print(f\"collecting {endpoint_name} data for season: {self.season}\")\n",
    "        teams = []\n",
    "        players= []\n",
    "        ex_set = set()\n",
    "        # if endpoint_name == 'traditional':\n",
    "        #     col_gid = 'gameId'\n",
    "        # else:\n",
    "        #     col_gid = 'GAME_ID'\n",
    "        col_gid = 'GAME_ID'\n",
    "        ## remove already gotten games\n",
    "        if path.exists(f'DATA/raw/players/{endpoint_name}/{endpoint_name}{self.season}.csv'):\n",
    "            try:\n",
    "                with open(f'DATA/raw/players/{endpoint_name}/{endpoint_name}{self.season}.csv', 'r') as f:\n",
    "                    pstats = pd.read_csv(f, dtype={col_gid: str})\n",
    "\n",
    "                #have to loop through to add leading 0's if not already present\n",
    "                ex_set = set()\n",
    "                for i in pstats[col_gid]:\n",
    "                    try:\n",
    "                        if i[:2] != '00':\n",
    "                            newi = '00'+i\n",
    "                            ex_set.add(newi)\n",
    "                        else:\n",
    "                            ex_set.add(i)\n",
    "                    except:\n",
    "                        print('gid_problem')\n",
    "            except Exception as e:\n",
    "                print(f\"Unable to exclude partial player data\\n\\t{e}\\n\")\n",
    "        else:\n",
    "            pstats = pd.DataFrame()\n",
    "\n",
    "        if path.exists(f'DATA/raw/teams/{endpoint_name}/{endpoint_name}{self.season}.csv'):\n",
    "            try:\n",
    "                with open(f'DATA/raw/teams/{endpoint_name}/{endpoint_name}{self.season}.csv', 'r') as f2:\n",
    "                    tstats = pd.read_csv(f2, dtype={col_gid: str})\n",
    "                #have to loop through to add leading 0's if not already present\n",
    "                ex_set2 = set()\n",
    "                for i in tstats[col_gid]:\n",
    "                    try:\n",
    "                        if i[:2] != '00':\n",
    "                            newi = '00'+i\n",
    "                            ex_set2.add(newi)\n",
    "                        else:\n",
    "                            ex_set2.add(i)\n",
    "                    except:\n",
    "                        print('gid_problem')\n",
    "                ex_set = ex_set.intersection(ex_set2)\n",
    "            except Exception as e:\n",
    "                print(f\"Unable to exclude partial player data\\n\\t{e}\\n\")\n",
    "        else:\n",
    "            tstats = pd.DataFrame()\n",
    "\n",
    "        print(f\"total number of games = {len(self.gidset)}\\nremoving {len(ex_set)} games from list\")\n",
    "        print(f\"still need {len(self.gidset - ex_set)}\")\n",
    "\n",
    "        gids = self.gidset-ex_set\n",
    "        if not gids:\n",
    "            print(f'all data present for {endpoint_name}_{self.season}\\n')\n",
    "            return 0\n",
    "        \n",
    "        count=0\n",
    "        statfunc = self.FD[endpoint_name]\n",
    "        for gid in gids:\n",
    "            try:\n",
    "                count+=1\n",
    "                game = statfunc(game_id=gid).get_data_frames()\n",
    "                players.append(game[0])\n",
    "                teams.append(game[1])\n",
    "            except Exception as e:\n",
    "                if not players:\n",
    "                    print(f\"ERROR, NO NEW DATA, FILES UNCHANGED,STILL NEED {len(ex_set)+count - len(self.gidset)} GAMES\\n\\t{e}\")\n",
    "                    return len(self.gidset) - len(ex_set)+count\n",
    "                else:\n",
    "                    print(f\"MADE IT THROUGH {count} GAMES OUT OF {len(gids)} GAMES BECAUSE OF \\n\\t{e}\\nRESULTING IN {len(ex_set)+count} GAMES OUT OF {len(self.gidset)} TOTAL\")\n",
    "                    new_pstats = pd.concat(players)\n",
    "                    new_tstats = pd.concat(teams)\n",
    "                    nsp = pd.concat([new_pstats, pstats], ignore_index=True)\n",
    "                    nst = pd.concat([new_tstats, tstats], ignore_index=True)\n",
    "                    \n",
    "                    self.write_out(endpoint_name, nst, nsp)\n",
    "                    break\n",
    "\n",
    "        if not players or not teams:\n",
    "            print('NO CHANGES?')\n",
    "            return 0\n",
    "            \n",
    "        new_pstats = pd.concat(players)\n",
    "        new_tstats = pd.concat(teams)\n",
    "        nsp = pd.concat([new_pstats, pstats], ignore_index=True)\n",
    "        nst = pd.concat([new_tstats, tstats], ignore_index=True)\n",
    "\n",
    "        print(f\"writing {len(new_tstats) / 2} games\\nDONE\\n\")\n",
    "\n",
    "        self.write_out(endpoint_name, nst, nsp)\n",
    "        return len(ex_set)+count - len(self.gidset)\n",
    "        \n",
    "\n",
    "    def Season_csv(self, endpoint_name):\n",
    "        teams = []\n",
    "        players= []\n",
    "        count=0\n",
    "        statfunc = self.FD[endpoint_name]\n",
    "        for gid in self.gidset:\n",
    "            try:\n",
    "                count+=1\n",
    "                game = statfunc(game_id=gid).get_data_frames()\n",
    "                players.append(game[0])\n",
    "                teams.append(game[1])\n",
    "            except Exception as e:\n",
    "                print(f\"ONLY MADE IT THROUGH {count} GAMES BECAUSE OF \\n\\t{e}\")\n",
    "                with open(f'DATA/raw/players/{endpoint_name}/PARTIAL_{endpoint_name}{self.season}.bin', 'wb') as f:\n",
    "                    pickle.dump(players, f)\n",
    "                with open(f'DATA/raw/teams/{endpoint_name}/PARTIAL_{endpoint_name}{self.season}.bin', 'wb') as f2:\n",
    "                    pickle.dump(teams, f2)\n",
    "                break\n",
    "        pstats = pd.concat(players)\n",
    "        tstats = pd.concat(teams)\n",
    "        return tstats, pstats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def append_game(statfunc, current_stats, gid, playerdata=False):\n",
    "    if playerdata:\n",
    "        game = statfunc(game_id=gid).get_data_frames()[0]\n",
    "        current_stats = pd.concat([current_stats,game])\n",
    "        return current_stats\n",
    "    else:\n",
    "        game = statfunc(game_id=gid).get_data_frames()[1]\n",
    "        current_stats = pd.concat([current_stats,game])\n",
    "        return current_stats\n",
    "def split_gid(gidset, nos):\n",
    "    rem = len(gidset)%nos\n",
    "    relist = [int(len(gidset)/nos)] * nos\n",
    "    relist[-1]+=rem\n",
    "    return relist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f63605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TEMP FIX GID MATCHING\n",
    "# sb = StatBucket()\n",
    "# # THIS MAY NEED TO BE SEASONS[i][:4] for some earlier seasons??\n",
    "# sb.update_log('2023-24')\n",
    "# sb.get_log_stats()\n",
    "# print(sb.gidset)\n",
    "\n",
    "\n",
    "# with open(f'DATA/raw/players/advanced/advanced2023-24.csv', 'r') as f:\n",
    "#     pstats = pd.read_csv(f, dtype={'GAME_ID': str})\n",
    "# print(pstats)\n",
    "# ex_set = set()\n",
    "# for i in pstats['GAME_ID']:\n",
    "#     if i[:2] != '00':\n",
    "#         newi = '00'+i\n",
    "#         ex_set.add(newi)\n",
    "#     else:\n",
    "#         ex_set.add(i)\n",
    "# print(ex_set - sb.gidset)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAYER DATA OR TEAM DATA\n",
    "PLAYER_DATA = False\n",
    "\n",
    "\n",
    "SEASONS = ['2010-11',\n",
    "           '2011-12',\n",
    "           '2012-13',\n",
    "           '2013-14',\n",
    "           '2014-15',\n",
    "           '2015-16',\n",
    "           '2016-17',\n",
    "           '2022-23',\n",
    "           '2023-24',\n",
    "           '2021-22',\n",
    "           '2017-18',\n",
    "           '2018-19',\n",
    "           '2019-20',\n",
    "           '2020-21',]\n",
    "\n",
    "# ['2010-11',\n",
    "#            '2011-12',\n",
    "#            '2012-13',\n",
    "#            '2013-14',\n",
    "#            '2014-15',\n",
    "#            '2015-16',\n",
    "#            '2016-17',\n",
    "#            '2017-18',\n",
    "#            '2018-19',\n",
    "#            '2019-20',\n",
    "#            '2020-21',\n",
    "#           '2021-22',\n",
    "#           '2022-23']\n",
    "\n",
    "FN = ['traditional']\n",
    "\n",
    "# FN = ['scoring',\n",
    "#     'advanced',\n",
    "#     'fourfactors',\n",
    "#      'misc']\n",
    "\n",
    "\n",
    "#      'scoring'\n",
    "#      'summary',\n",
    "#      'traditional'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c74871",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DIFFERENT SEASON_CSV_FUNCTION:\n",
    "\n",
    "done_check = dict()\n",
    "for ses in SEASONS:\n",
    "    for f in FN:\n",
    "        done_check[ses+f] = 1\n",
    "\n",
    "def check_done(res_d):\n",
    "    for k in res_d:\n",
    "        if res_d[k] != 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "DONE = False\n",
    "loop_count=0\n",
    "while not DONE:\n",
    "    print(f\"loop: {loop_count}\")\n",
    "    for i in range(len(SEASONS)):\n",
    "        try:\n",
    "            sb = StatBucket()\n",
    "            # THIS MAY NEED TO BE SEASONS[i][:4] for some earlier seasons??\n",
    "            sb.update_log(SEASONS[i])\n",
    "            sb.get_log_stats()\n",
    "            for j in FN:\n",
    "                if not done_check[SEASONS[i]+j]:\n",
    "                    continue\n",
    "                # if path.exists(f'DATA/raw/teams/{j}/{j}{SEASONS[i]}.csv'):\n",
    "                #     print(f\"SKIPPING teams/{j}/{j}{SEASONS[i]}, already exists\")\n",
    "                #     continue\n",
    "\n",
    "                if not len(sb.gidset):\n",
    "                    print(f'error with {SEASONS[i]}, no game ids')\n",
    "                    print(sb.outcomes)\n",
    "                    break\n",
    "                \n",
    "                if not path.exists(f'DATA/raw/log/log_{SEASONS[i]}.csv'):\n",
    "                    sb.clog.sort_values('TEAM_ID', inplace=True, kind='mergesort')\n",
    "                    sb.clog.sort_values('GAME_ID', inplace=True, kind='mergesort')\n",
    "                    sb.clog.to_csv(f'DATA/raw/log/log_{SEASONS[i]}.csv', index=False)\n",
    "                    \n",
    "                done_check[SEASONS[i]+j] = sb.Season_csv_update(j)\n",
    "        except Exception as e:\n",
    "            print(f'ERROR with {SEASONS[i]} \\n\\t{e}')\n",
    "    loop_count+=1\n",
    "    DONE = check_done(done_check)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"FINISHED WITH {SEASONS} and {FN}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.leaguegamefinder.LeagueGameFinder(season_nullable='2020-21').get_data_frames()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780bcaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR UPDATING DATA:\n",
    "\n",
    "for i in range(len(SEASONS)):\n",
    "    print(SEASONS[i])\n",
    "    sb = StatBucket()\n",
    "    sb.update_log(SEASONS[i])\n",
    "    sb.get_log_stats()\n",
    "    gidset = set(sb.outcomes.keys())\n",
    "    if not path.exists(f'DATA/raw/log/log_{SEASONS[i]}.csv'):\n",
    "        sb.clog.sort_values('TEAM_ID', inplace=True, kind='mergesort')\n",
    "        sb.clog.sort_values('GAME_ID', inplace=True, kind='mergesort')\n",
    "        sb.clog.to_csv(f'DATA/raw/log/log_{SEASONS[i]}.csv', index=False)\n",
    "\n",
    "    for j in FN:\n",
    "        print(j)\n",
    "\n",
    "        if not len(gidset):\n",
    "            print(f'error with {SEASONS[i]}, no game ids')\n",
    "            print(sb.outcomes)\n",
    "            break\n",
    "        nst, nsp = sb.Season_csv_update(j)\n",
    "        # nst.sort_values('TEAM_ID', inplace=True, kind='mergesort')\n",
    "        # nst.sort_values('GAME_ID', inplace=True, kind='mergesort')\n",
    "        # nst.to_csv(f'DATA/raw/teams/{j}/{j}{SEASONS[i]}.csv')\n",
    "        # nsp.sort_values('TEAM_ID', inplace=True, kind='mergesort')\n",
    "        # nsp.sort_values('GAME_ID', inplace=True, kind='mergesort')\n",
    "        # nsp.to_csv(f'DATA/raw/players/{j}/{j}{SEASONS[i]}.csv')\n",
    "\n",
    "        # IF V3\n",
    "        # nst.sort_values('teamId', inplace=True, kind='mergesort')\n",
    "        # nst.sort_values('gameId', inplace=True, kind='mergesort')\n",
    "        # nst.to_csv(f'DATA/raw/teams/{j}/{j}{SEASONS[i]}.csv')\n",
    "        # nsp.sort_values('teamId', inplace=True, kind='mergesort')\n",
    "        # nsp.sort_values('gameId', inplace=True, kind='mergesort')\n",
    "        # nsp.to_csv(f'DATA/raw/players/{j}/{j}{SEASONS[i]}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "nst.sort_values('teamId', inplace=True, kind='mergesort')\n",
    "nst.sort_values('gameId', inplace=True, kind='mergesort')\n",
    "nst.to_csv(f'DATA/raw/teams/{j}/{j}{SEASONS[i]}.csv')\n",
    "nsp.sort_values('teamId', inplace=True, kind='mergesort')\n",
    "nsp.sort_values('gameId', inplace=True, kind='mergesort')\n",
    "nsp.to_csv(f'DATA/raw/players/{j}/{j}{SEASONS[i]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsp['gameId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0d5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "nst['gameId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = ep.boxscoretraditionalv3.BoxScoreTraditionalV3(game_id='0022300709').get_data_frames()\n",
    "players = game[0]\n",
    "teams = game[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5987d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "nst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0765e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "nst.sort_values('teamId', inplace=True, kind='mergesort')\n",
    "nst.sort_values('gameId', inplace=True, kind='mergesort')\n",
    "nst.to_csv(f'DATA/raw/teams/{j}/{j}{SEASONS[i]}.csv')\n",
    "nsp.sort_values('teamId', inplace=True, kind='mergesort')\n",
    "nsp.sort_values('gameId', inplace=True, kind='mergesort')\n",
    "nsp.to_csv(f'DATA/raw/players/{j}/{j}{SEASONS[i]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9abcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76914dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99667688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'DATA/raw/players/traditional/PARTIAL_traditional2023-24.bin', 'rb') as f:\n",
    "    player_df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c8e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'teams100.bin', 'rb') as f2:\n",
    "    team_df = pickle.load(f2)\n",
    "\n",
    "\n",
    "# with open(f'DATA/raw/teams/traditional/PARTIAL_traditional2023-24.bin', 'rb') as f2:\n",
    "#     team_df = pickle.load(f2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd3a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_player = pd.concat(player_df)\n",
    "new_team = pd.concat(team_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6dea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new['gameId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46444feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in player_df:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SEASON='2023-24'\n",
    "\n",
    "sb = StatBucket()\n",
    "# THIS MAY NEED TO BE SEASONS[i][:4] for some earlier seasons??\n",
    "sb.update_log(SEASON)\n",
    "sb.get_log_stats()\n",
    "\n",
    "# if not path.exists(f'DATA/raw/log/log_{SEASON}.csv'):\n",
    "sb.clog.sort_values('TEAM_ID', inplace=True, kind='mergesort')\n",
    "sb.clog.sort_values('GAME_ID', inplace=True, kind='mergesort')\n",
    "sb.clog.to_csv(f'DATA/raw/log/log_{SEASON}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb68582",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ep.leaguegamefinder.LeagueGameFinder(season_nullable=SEASON).get_data_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    new = x + 10\n",
    "except:\n",
    "    print('ag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f41fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
